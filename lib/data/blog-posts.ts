import { BlogPost } from '../types';

export const blogPosts: BlogPost[] = [
  {
    id: 'python-libraries-2025',
    slug: 'essential-python-libraries-data-science-2025',
    title: '5 Essential Python Libraries for Data Science in 2025',
    excerpt: 'Discover the must-have Python libraries that every data scientist should master to stay competitive in the evolving field of data science.',
    content: `
# 5 Essential Python Libraries for Data Science in 2025

Data science continues to evolve rapidly, and staying updated with the essential tools is crucial for success. Here are the five Python libraries you absolutely need to master in 2025.

## 1. Pandas - Data Manipulation Powerhouse

Pandas remains the cornerstone of data manipulation in Python. With its intuitive DataFrame structure, it makes data cleaning, transformation, and analysis incredibly efficient.

\`\`\`python
import pandas as pd
df = pd.read_csv('data.csv')
df_cleaned = df.dropna().groupby('category').mean()
\`\`\`

## 2. Scikit-learn - Machine Learning Made Simple

For machine learning, Scikit-learn provides a consistent API across dozens of algorithms. From preprocessing to model evaluation, it's your go-to library.

\`\`\`python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y)
model = RandomForestClassifier()
model.fit(X_train, y_train)
\`\`\`

## 3. NumPy - Numerical Computing Foundation

NumPy powers nearly every numerical operation in Python. Its array objects and mathematical functions are essential for performance-critical operations.

## 4. Matplotlib & Seaborn - Visualization Duo

Creating compelling visualizations is key to communicating insights. Matplotlib provides granular control while Seaborn offers beautiful statistical plots out of the box.

## 5. Streamlit - Rapid Dashboard Development

Streamlit has revolutionized how data scientists create interactive dashboards. Build beautiful web apps in pure Python without HTML/CSS knowledge.

## Conclusion

Mastering these five libraries will give you a solid foundation for tackling most data science challenges in 2025. Start with Pandas and NumPy, then progress to machine learning with Scikit-learn, and finally create impressive visualizations and dashboards.
    `,
    author: 'M. Kashif Sultan',
    date: '2025-01-15',
    readTime: '5 min read',
    tags: ['Python', 'Data Science', 'Libraries', 'Tutorial'],
    featured: true,
  },
  {
    id: 'first-ml-model',
    slug: 'how-to-build-first-machine-learning-model',
    title: 'How to Build Your First Machine Learning Model',
    excerpt: 'A beginner-friendly guide to building your first machine learning model from scratch, covering data preparation to model deployment.',
    content: `
# How to Build Your First Machine Learning Model

Starting your machine learning journey can feel overwhelming, but building your first model is simpler than you think. Let's walk through the process step by step.

## Step 1: Define Your Problem

Before diving into code, clearly define what you want to predict. Are you classifying emails as spam, predicting house prices, or forecasting sales?

## Step 2: Gather and Explore Data

Quality data is the foundation of any ML model. You can find datasets on:
- Kaggle
- UCI Machine Learning Repository
- Government open data portals

\`\`\`python
import pandas as pd
data = pd.read_csv('your_data.csv')
print(data.head())
print(data.describe())
\`\`\`

## Step 3: Prepare Your Data

Data preparation includes:
- Handling missing values
- Encoding categorical variables
- Feature scaling
- Train-test split

\`\`\`python
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

X = data.drop('target', axis=1)
y = data['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
\`\`\`

## Step 4: Choose and Train a Model

Start simple with logistic regression or decision trees before moving to complex models.

\`\`\`python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train_scaled, y_train)
\`\`\`

## Step 5: Evaluate Your Model

Use appropriate metrics to assess performance:
- Classification: Accuracy, Precision, Recall, F1-Score
- Regression: MAE, RMSE, RÂ²

\`\`\`python
from sklearn.metrics import accuracy_score, classification_report

y_pred = model.predict(X_test_scaled)
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(classification_report(y_test, y_pred))
\`\`\`

## Step 6: Improve and Deploy

Experiment with different algorithms, tune hyperparameters, and when satisfied, deploy your model using Flask, FastAPI, or Streamlit.

## Conclusion

Building your first ML model is a significant milestone. Remember: start simple, iterate often, and focus on understanding the fundamentals before tackling complex architectures.
    `,
    author: 'M. Kashif Sultan',
    date: '2025-01-10',
    readTime: '7 min read',
    tags: ['Machine Learning', 'Tutorial', 'Beginner', 'Python'],
    featured: true,
  },
  {
    id: 'streamlit-vs-dash',
    slug: 'streamlit-vs-dash-choosing-dashboard-tool',
    title: 'Streamlit vs Dash: Choosing the Right Dashboard Tool',
    excerpt: 'Compare two popular Python dashboard frameworks to help you choose the best tool for your data visualization needs.',
    content: `
# Streamlit vs Dash: Choosing the Right Dashboard Tool

When building interactive dashboards in Python, Streamlit and Dash are the two most popular choices. Let's compare them to help you make an informed decision.

## Streamlit: Simplicity First

**Pros:**
- Incredibly simple to learn
- Pure Python - no HTML/CSS required
- Rapid prototyping
- Built-in widgets and components
- Automatic reactivity

**Cons:**
- Less customization flexibility
- Limited layout control
- Performance issues with very large datasets

**Best For:** Quick prototypes, internal tools, data exploration dashboards

\`\`\`python
import streamlit as st
import pandas as pd

st.title("My Dashboard")
data = pd.read_csv("data.csv")
st.line_chart(data)
\`\`\`

## Dash: Power and Flexibility

**Pros:**
- Full customization with HTML/CSS
- Production-ready
- Better performance for large datasets
- Extensive callback system
- Enterprise support available

**Cons:**
- Steeper learning curve
- More verbose code
- Requires HTML/CSS knowledge for advanced layouts

**Best For:** Production applications, customer-facing dashboards, complex interactive visualizations

\`\`\`python
from dash import Dash, html, dcc
import plotly.express as px

app = Dash(__name__)
app.layout = html.Div([
    html.H1("My Dashboard"),
    dcc.Graph(figure=px.line(data, x='date', y='value'))
])
\`\`\`

## The Verdict

**Choose Streamlit if:**
- You need to build something quickly
- Your audience is internal (data team, stakeholders)
- You want to focus on Python and avoid web dev

**Choose Dash if:**
- You need production-grade deployment
- You require extensive customization
- You're building customer-facing applications

## Hybrid Approach

Many teams use both: Streamlit for rapid prototyping and internal tools, Dash for production deployments. Start with Streamlit to validate your concept, then migrate to Dash if needed.

## Conclusion

Both tools are excellent choices. Your decision should be based on your specific use case, team skills, and time constraints. For most data scientists, starting with Streamlit is the right move.
    `,
    author: 'M. Kashif Sultan',
    date: '2025-01-05',
    readTime: '6 min read',
    tags: ['Streamlit', 'Dash', 'Dashboard', 'Comparison'],
    featured: false,
  },
  {
    id: 'predictive-analytics-guide',
    slug: 'predictive-analytics-beginners-guide',
    title: "Predictive Analytics: A Beginner's Guide",
    excerpt: 'Learn the fundamentals of predictive analytics and how businesses use it to make data-driven decisions.',
    content: `
# Predictive Analytics: A Beginner's Guide

Predictive analytics is transforming how businesses make decisions. This guide will introduce you to its core concepts and applications.

## What is Predictive Analytics?

Predictive analytics uses historical data, statistical algorithms, and machine learning to identify the likelihood of future outcomes. It's about making informed predictions rather than guessing.

## Key Techniques

### 1. Regression Analysis
Predicts continuous outcomes like sales figures or temperatures.

### 2. Classification
Categorizes data into predefined groups (spam/not spam, fraud/legitimate).

### 3. Time Series Analysis
Forecasts future values based on historical time-ordered data.

### 4. Clustering
Groups similar data points to identify patterns and segments.

## Real-World Applications

**Retail:** Forecast demand, optimize inventory, personalize recommendations

**Finance:** Credit scoring, fraud detection, risk assessment

**Healthcare:** Disease prediction, patient readmission rates, treatment outcomes

**Marketing:** Customer churn prediction, campaign optimization, lead scoring

## Building a Predictive Model

\`\`\`python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Load data
data = pd.read_csv('sales_data.csv')

# Prepare features and target
X = data[['feature1', 'feature2', 'feature3']]
y = data['sales']

# Split and train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model = RandomForestRegressor(n_estimators=100)
model.fit(X_train, y_train)

# Evaluate
predictions = model.predict(X_test)
mse = mean_squared_error(y_test, predictions)
print(f"Model MSE: {mse}")
\`\`\`

## Common Pitfalls to Avoid

1. **Overfitting:** Model performs well on training data but poorly on new data
2. **Data Leakage:** Including future information in training data
3. **Ignoring Domain Knowledge:** Statistical models need business context
4. **Poor Data Quality:** Garbage in, garbage out

## Getting Started

1. Learn Python and basic statistics
2. Master pandas and scikit-learn
3. Work on real datasets from Kaggle
4. Build end-to-end projects
5. Deploy your models

## Conclusion

Predictive analytics is a powerful tool that's becoming increasingly accessible. Start with simple projects, focus on understanding the fundamentals, and gradually tackle more complex problems.
    `,
    author: 'M. Kashif Sultan',
    date: '2024-12-28',
    readTime: '8 min read',
    tags: ['Predictive Analytics', 'Machine Learning', 'Data Science', 'Tutorial'],
    featured: false,
  },
];

// Get featured blog posts
export const getFeaturedPosts = (): BlogPost[] => {
  return blogPosts.filter(post => post.featured);
};

// Get blog post by slug
export const getPostBySlug = (slug: string): BlogPost | undefined => {
  return blogPosts.find(post => post.slug === slug);
};

// Get recent posts
export const getRecentPosts = (limit: number = 3): BlogPost[] => {
  return [...blogPosts]
    .sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime())
    .slice(0, limit);
};

// Get posts by tag
export const getPostsByTag = (tag: string): BlogPost[] => {
  return blogPosts.filter(post =>
    post.tags.some(t => t.toLowerCase() === tag.toLowerCase())
  );
};

// Get all tags
export const getAllTags = (): string[] => {
  const tags = new Set<string>();
  blogPosts.forEach(post => {
    post.tags.forEach(tag => tags.add(tag));
  });
  return Array.from(tags);
};
